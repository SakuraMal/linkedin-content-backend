# fly.toml app configuration file generated for linkedin-content-backend on 2025-03-09T09:50:40Z
#
# See https://fly.io/docs/reference/configuration/ for information about how to use this file.
#

app = "linkedin-content-backend"
primary_region = "mad"

[build]
  dockerfile = "Dockerfile.python"

[env]
  PORT = "8080"
  PYTHONUNBUFFERED = "1"
  FLASK_APP = "wsgi.py"
  FLASK_ENV = "production"
  ENVIRONMENT = "production"
  CORS_ORIGINS = "http://localhost:3000,https://linkedin-content-frontend.vercel.app"
  DEBUG_VIDEO = "true"

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 1
  processes = ["app"]

  [http_service.concurrency]
    type = "connections"
    hard_limit = 25
    soft_limit = 20

  [[http_service.ports]]
    handlers = ["http"]
    port = 80

  [[http_service.ports]]
    handlers = ["tls", "http"]
    port = 443

  [http_service.ports.tls_options]
    alpn = ["http/1.1"]
    versions = ["TLSv1.2", "TLSv1.3"]

  [[http_service.tcp_checks]]
    interval = "15s"
    timeout = "2s"
    grace_period = "1s"

  [[http_service.checks]]
    interval = "30s"
    timeout = "5s"
    grace_period = "10s"
    method = "GET"
    path = "/health"
    protocol = "http"
    tls_skip_verify = false

  [[http_service.checks]]
    interval = "30s"
    timeout = "5s"
    grace_period = "10s"
    method = "GET"
    path = "/"
    protocol = "http"
    tls_skip_verify = false

[[vm]]
  memory = '4gb'
  cpu_kind = 'shared'
  cpus = 2
  memory_mb = 4096

[metrics]
  port = 9091
  path = "/metrics"
